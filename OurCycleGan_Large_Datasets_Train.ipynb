{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.models as modelss\n",
    "\n",
    "import copy\n",
    "\n",
    "from models import Generator\n",
    "from models import Discriminator\n",
    "from utils import ReplayBuffer\n",
    "from utils import LambdaLR\n",
    "from utils import Logger\n",
    "from utils import weights_init_normal\n",
    "from easydict import EasyDict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_dir = '/datasets/ee285f-public/flickr_landscape/'\n",
    "wikiar_dir = '/datasets/ee285f-public/wikiart/wikiart'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = EasyDict()\n",
    "\n",
    "opt.epoch = 0\n",
    "opt.n_epochs = 1\n",
    "opt.batchSize = 5\n",
    "opt.lr = 0.0003\n",
    "opt.decay_epoch = 1\n",
    "opt.size = 190\n",
    "opt.input_nc = 3 \n",
    "opt.output_nc = 3\n",
    "opt.lambda_identity = 0.5\n",
    "opt.lambda_A = 10 \n",
    "opt.lambda_B = 10 #back to color is given more importance\n",
    "opt.cuda = device\n",
    "opt.generator_A2B = 'output0/netG_A2B.pth'\n",
    "opt.generator_B2A = 'output0/netG_B2A.pth'\n",
    "opt.discriminator_A = 'output0/netD_A.pth'\n",
    "opt.discriminator_B = 'output0/netD_B.pth'\n",
    "opt.loss_dir = 'output0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_A2B = Generator(opt.input_nc, opt.output_nc).to(device)\n",
    "netG_B2A = Generator(opt.output_nc, opt.input_nc).to(device) \n",
    "netD_A = Discriminator(opt.input_nc).to(device) \n",
    "netD_B = Discriminator(opt.output_nc).to(device) \n",
    "\n",
    "netG_A2B.apply(weights_init_normal)\n",
    "netG_B2A.apply(weights_init_normal)\n",
    "netD_A.apply(weights_init_normal)\n",
    "netD_B.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGanDatasets(td.Dataset):\n",
    "    \n",
    "    def __init__(self, wikiart_root_dir, flickr_root_dir, mode = \"train\", image_size = opt.size): \n",
    "        super(CycleGanDatasets, self).__init__() \n",
    "        self.image_size = image_size\n",
    "        self.mode = mode\n",
    "        self.wikiart_images_dir = wikiart_root_dir\n",
    "        self.flickr_images_dir = flickr_root_dir\n",
    "        self.wikiart_files = os.listdir(self.wikiart_images_dir)\n",
    "        self.flickr_files = os.listdir(self.flickr_images_dir)\n",
    "        \n",
    "        wikiart_length = len(self.wikiart_files)\n",
    "        flickr_length = len(self.flickr_files)\n",
    "        global_length = np.maximum(wikiart_length, flickr_length)\n",
    "        global_length = np.minimum(global_length, 900)\n",
    "        global_step = int(0.1*global_length)\n",
    "        if wikiart_length < global_length:\n",
    "            diff = global_length - wikiart_length\n",
    "            for i in range(diff):\n",
    "                rand_idx = np.random.randint(wikiart_length)\n",
    "                self.wikiart_files.append(self.wikiart_files[rand_idx])\n",
    "        elif flickr_length < global_length:\n",
    "            diff = global_length - flickr_length\n",
    "            for i in range(diff):\n",
    "                rand_idx = np.random.randint(flickr_length)\n",
    "                self.flickr_files.append(self.flickr_files[rand_idx])\n",
    "        \n",
    "        random.seed(0)\n",
    "        random.shuffle(self.wikiart_files)\n",
    "        random.shuffle(self.flickr_files)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.wikiart_img_path = self.wikiart_files[0 : 7*global_step]\n",
    "            self.flickr_img_path = self.flickr_files[0 : 7*global_step]\n",
    "        elif self.mode == 'test':\n",
    "            self.wikiart_img_path = self.wikiart_files[7*global_step: 8*global_step]\n",
    "            self.flickr_img_path = self.flickr_files[7*global_step : 8*global_step]\n",
    "        elif self.mode == 'val':\n",
    "            self.wikiart_img_path = self.wikiart_files[8*global_step : 10*global_step]\n",
    "            self.flickr_img_path = self.flickr_files[8*global_step : 10*global_step]    \n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.wikiart_img_path)\n",
    "        \n",
    "    def __getitem__(self, idx): \n",
    "        wikiart_img_path = os.path.join(self.wikiart_images_dir, self.wikiart_img_path[idx])\n",
    "        flickr_img_path = os.path.join(self.flickr_images_dir, self.flickr_img_path[idx])\n",
    "        wikiart_img = Image.open(wikiart_img_path)\n",
    "        flickr_img = Image.open(flickr_img_path)\n",
    "        transform = tv.transforms.Compose([\n",
    "            tv.transforms.Resize(int(1.2*self.image_size)),\n",
    "            tv.transforms.RandomCrop(self.image_size),\n",
    "            tv.transforms.ToTensor(),\n",
    "            tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        x = transform(wikiart_img)\n",
    "        y = transform(flickr_img)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myimshow(image, ax=plt):\n",
    "    image = image.to('cpu').numpy() \n",
    "#     image = image.numpy()\n",
    "    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1]) \n",
    "    image = (image + 1) / 2 \n",
    "    image[image < 0] = 0 \n",
    "    image[image > 1] = 1\n",
    "    ax.figure()\n",
    "    h = ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "import sys\n",
    "\n",
    "\n",
    "class demo_module():\n",
    "    \n",
    "    def __init__(self, netG_A2B, netG_B2A, netD_A, netD_B, opt, test_loader, output_dir):\n",
    "        \n",
    "        loss_G = [[], []]\n",
    "        loss_G_identity = [[], []]\n",
    "        loss_G_GAN = [[], []]\n",
    "        loss_G_cycle = [[], []]\n",
    "        loss_D = [[], []]\n",
    "                \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(output_dir, \"checkpoint.pth.tar\")\n",
    "        config_path = os.path.join(output_dir, \"config.txt\")\n",
    "        \n",
    "        print(checkpoint_path)\n",
    "        \n",
    "        locs = {k: v for k, v in locals().items() if k is not 'self'}\n",
    "        self.__dict__.update(locs)\n",
    "\n",
    "        if os.path.isfile(config_path):\n",
    "            self.load()\n",
    "        else:\n",
    "            self.save()\n",
    "            \n",
    "        num_epochs = self.epoch()\n",
    "\n",
    "    \n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the current state of the experiment.\"\"\"\n",
    "        return {'netG_A2B': self.netG_A2B.state_dict(),\n",
    "                'netG_B2A': self.netG_B2A.state_dict(),\n",
    "                'netD_A': self.netD_A.state_dict(),\n",
    "                'netD_B': self.netD_B.state_dict(),\n",
    "                }\n",
    "\n",
    "    def load_state_dict(self, checkpoint):\n",
    "        \"\"\"Loads the experiment from the input checkpoint.\"\"\"\n",
    "        self.netG_A2B.load_state_dict(checkpoint['netG_A2B'])\n",
    "        self.netG_B2A.load_state_dict(checkpoint['netG_B2A'])\n",
    "        self.netD_A.load_state_dict(checkpoint['netD_A'])\n",
    "        self.netD_B.load_state_dict(checkpoint['netD_B'])\n",
    "        \n",
    "        self.loss_G[0] = list(np.load('{}/loss_G.npy'.format(self.output_dir))[0])\n",
    "        self.loss_G[1] = list(np.load('{}/loss_G.npy'.format(self.output_dir))[1])\n",
    "\n",
    "        self.loss_G_identity[0] = list(np.load('{}/loss_G_identity.npy'.format(self.output_dir))[0])\n",
    "        self.loss_G_identity[1] = list(np.load('{}/loss_G_identity.npy'.format(self.output_dir))[1])\n",
    "        \n",
    "        self.loss_G_GAN[0] = list(np.load('{}/loss_G_GAN.npy'.format(self.output_dir))[0])\n",
    "        self.loss_G_GAN[1] = list(np.load('{}/loss_G_GAN.npy'.format(self.output_dir))[1])\n",
    "        \n",
    "        self.loss_G_cycle[0] = list(np.load('{}/loss_G_cycle.npy'.format(self.output_dir))[0])\n",
    "        self.loss_G_cycle[1] = list(np.load('{}/loss_G_cycle.npy'.format(self.output_dir))[1])\n",
    "\n",
    "        self.loss_D[0] = list(np.load('{}/loss_D.npy'.format(self.output_dir))[0])\n",
    "        self.loss_D[1] = list(np.load('{}/loss_D.npy'.format(self.output_dir))[1])\n",
    "\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"Saves the experiment on disk, i.e, create/update the last checkpoint.\"\"\"\n",
    "        \n",
    "        np.save('{}/loss_G'.format(self.output_dir), np.asarray(self.loss_G))\n",
    "        np.save('{}/loss_G_identity'.format(self.output_dir), np.asarray(self.loss_G_identity))\n",
    "        np.save('{}/loss_G_GAN'.format(self.output_dir), np.asarray(self.loss_G_GAN))\n",
    "        np.save('{}/loss_G_cycle'.format(self.output_dir), np.asarray(self.loss_G_cycle))\n",
    "        np.save('{}/loss_D'.format(self.output_dir), np.asarray(self.loss_D))\n",
    "        \n",
    "        torch.save(self.state_dict(), self.checkpoint_path)\n",
    "        with open(self.config_path, 'w') as f:\n",
    "            print(self, file=f)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"Loads the experiment from the last checkpoint saved on disk.\"\"\"\n",
    "        checkpoint = torch.load(self.checkpoint_path,\n",
    "                                map_location=self.opt.cuda)\n",
    "        self.load_state_dict(checkpoint)\n",
    "        del checkpoint\n",
    "\n",
    "    def epoch(self):\n",
    "        \"\"\"Returns the number of epochs already performed.\"\"\"\n",
    "        return len(self.loss_G[0])\n",
    "\n",
    "   \n",
    "    def normalize(self, data):\n",
    "\n",
    "        return (data - torch.min(data))/(torch.max(data)-torch.min(data))\n",
    "      \n",
    "    \n",
    "    def demo(self, wikiart_subclass, flickr_subclass):\n",
    "        self.netG_A2B.eval()\n",
    "        self.netG_B2A.eval()\n",
    "\n",
    "        Tensor = torch.cuda.FloatTensor if self.opt.cuda else torch.Tensor\n",
    "        input_A = Tensor(self.opt.batchSize, self.opt.input_nc, self.opt.size, self.opt.size)\n",
    "        input_B = Tensor(self.opt.batchSize, self.opt.output_nc, self.opt.size, self.opt.size)\n",
    "        \n",
    "        img_out_list = []\n",
    "        \n",
    "        for i, batch in enumerate(self.test_loader):#test_loader\n",
    "            # Set model input\n",
    "            img_list = []\n",
    "            real_A = Variable(input_A.copy_(batch[0]))\n",
    "            real_B = Variable(input_B.copy_(batch[1]))\n",
    "\n",
    "            # Generate output\n",
    "            fake_B = self.netG_A2B(real_A).data\n",
    "            fake_A = self.netG_B2A(real_B).data\n",
    "\n",
    "            img_out_list.append(torch.cat((self.normalize(real_A.data[0]), self.normalize(fake_B[0]), \\\n",
    "                                           self.normalize(real_B.data[0]), self.normalize(fake_A[0])),  \\\n",
    "                                           dim=2).cpu().detach().numpy())    \n",
    "\n",
    "            if i == 2:\n",
    "                break\n",
    "                \n",
    "        for j in range(len(img_out_list)):\n",
    "            img_out_list[j] = np.moveaxis(img_out_list[j], [0, 1, 2], [2, 0, 1]) \n",
    "        temp_img = np.concatenate(img_out_list, axis = 0)\n",
    "        plt.figure(figsize=(70,35))\n",
    "        plt.title('Style: '+wikiart_subclass +'  Content: '+flickr_subclass+'\\n', fontsize=40)\n",
    "        \n",
    "        plt.imshow(temp_img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def save_show_test_images(self):\n",
    "        test_out_dir = self.output_dir + '/test'\n",
    "        files_files = os.listdir(test_out_dir)\n",
    "        idx_list = []\n",
    "        a = 0\n",
    "        for idx in range(a, a+6):\n",
    "            idx_list.append(os.path.join(test_out_dir, files_files[idx]))\n",
    "        img_list = []\n",
    "        for item in idx_list:\n",
    "            img_list.append(np.array(Image.open(item)))\n",
    "        \n",
    "        print(img_list[0].shape)\n",
    "        \n",
    "        return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp0 = train_module(netG_A2B, netG_B2A, netD_A, netD_B, opt, train_loader, \\\n",
    "                    val_loader, test_loader, criterion_identity, \\\n",
    "                    criterion_GAN, criterion_cycle , optimizer_G, \\\n",
    "                    optimizer_D, output_dir = 'check_'+wikiart_subclass+'_'+flickr_subclass+'_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run below if you want to train, otherwise just comment it\n",
    "exp0.train(num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_G_read = np.load('check0/loss_G.npy')\n",
    "# x = range(len(loss_G_read[0]))\n",
    "# plt.plot(x, loss_G_read[0], x, loss_G_read[1])\n",
    "exp0.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp0.demo(wikiart_subclass, flickr_subclass)\n",
    "# from left to right: (real landscape, fake landscape, real artworks, fake artworks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
